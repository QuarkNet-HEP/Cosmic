{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the Parsl library and the various components we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "from parsl.config import Config\n",
    "from parsl.executors.threads import ThreadPoolExecutor\n",
    "from parsl.app.app import bash_app,python_app\n",
    "from parsl import File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use Parsl's functions, we'll need to define and then load its configuration as a Parsl `Config` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7fafea9cdfd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(\n",
    "    executors=[ThreadPoolExecutor()],\n",
    "    lazy_errors=True\n",
    ")\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the Python functions we'll use for the workflow.  By decorating each function as an App, Parsl will be able to parallelize them during execution.  We define these as `bash` Apps because we'll use the functions to invoke Perl scripts in the same way we would from the Bash shell's command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Apps ##\n",
    "@bash_app\n",
    "def WireDelay(threshIn='', outputs=[], geoDir='', daqId='', fw='', stdout='stdout.txt', stderr='stderr.txt'):\n",
    "        return 'perl ./perl/WireDelay.pl %s %s %s %s %s' %(threshIn,outputs[0],geoDir,daqId,fw)\n",
    "\n",
    "@bash_app\n",
    "def Combine(inputs=[], outputs=[], stdout='stdout.txt', stderr='stderr.txt'):\n",
    "        return 'perl ./perl/Combine.pl ' + ' '.join(inputs) + ' ' + str(outputs[0])\n",
    "\n",
    "@bash_app\n",
    "def Sort(inputs=[], outputs=[], key1='1', key2='1', stdout='stdout.txt', stderr='stderr.txt'):\n",
    "        return 'perl ./perl/Sort.pl %s %s %s %s' %(inputs[0], outputs[0], key1, key2)\n",
    "\n",
    "@bash_app\n",
    "def EventSearch(inputs=[], outputs=[], gate='', detCoinc='2', chanCoinc='2', eventCoinc='2', stdout='stdout.txt', stderr='stderr.txt'):\n",
    "        return 'perl ./perl/EventSearch.pl %s %s %s %s %s %s' %(inputs[0],outputs[0],gate,detCoinc,chanCoinc,eventCoinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step before the workflow itself is to define the parameters that the Apps will require as inputs.  When used in the Cosmic Ray e-Lab, these are selected by the user through the interface.\n",
    "\n",
    "For this analysis, the necessary parameters are:\n",
    "* **thresholdAll** -- the names and locations of the threshold files that the analysis uses as input data\n",
    "* **wireDelayData** -- what we'd like the analysis to name the Wire Delay files that will be created during execution\n",
    "* **geoDir** -- the location of the directory that contains the geography (`.geo`) files of the relevant detectors\n",
    "* **detectors** -- the DAQ IDs of all detectors used in the analysis\n",
    "* **firmwares** -- the versions of the firmware used on each detector's DAQ board. This can affect how the data from that detector is interpreted!\n",
    "* **combineOut** -- what we'd like the analysis to name the Combined Data file that will be created during execution\n",
    "* **sort_sortKey1**, **sort_sortKey2** -- which columns the Sort() function should sort in ascending order.  **sort_sortKey1** is the primary sort column, while **sort_sortKey2** is the secondary sort column.\n",
    "* **sortOut** - what we'd like the analysis to name the Sorted Data file that will be created during execution\n",
    "* **gate** -- the size of the gate in nanoseconds.  The analysis will search for events that are coincident within this time interval\n",
    "* **detectorCoincidence** -- how many different detectors should record hits within the gate interval in order for it to qualify as a candidate event\n",
    "* **channelCoincidence** -- how many different channels on each detector should record hits within the gate interval in order for it to qualify as a candidate event\n",
    "* **eventCoincidence** -- how many hits a channel should record within the gate interval in order for it to qualify as a candidate event\n",
    "* **eventCandidates** -- what we'd like the analysis to name the Event Candidates file that will be created as the end result of its execution\n",
    "\n",
    "Since these parameters will be used to construct command-line invocations of Perl scripts, we define them all as strings (even the numbers!  Python itself won't be doing any math with them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis Parameters ##\n",
    "# Define what are typically the command-line arguments\n",
    "\n",
    "# For WireDelay:\n",
    "thresholdAll = ('files/6119.2016.0104.1.thresh', 'files/6203.2016.0104.1.thresh')\n",
    "wireDelayData = ('6119.2016.0104.1.wd', '6203.2016.0104.1.wd')\n",
    "geoDir = './geo'\n",
    "detectors = ('6119', '6203')\n",
    "firmwares = ('1.12', '1.12')\n",
    "\n",
    "# For Combine:\n",
    "combineOut = 'combineOut'\n",
    "\n",
    "# For Sort:\n",
    "sort_sortKey1 = '2'\n",
    "sort_sortKey2 = '3'\n",
    "sortOut = 'sortOut'\n",
    "\n",
    "# For EventSearch:\n",
    "gate = '1000'\n",
    "detectorCoincidence = '1'\n",
    "channelCoincidence = '2'\n",
    "eventCoincidence = '2'\n",
    "eventCandidates = 'eventCandidates'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to call on our Apps to do their data crunching. Note carefully the use of `futures` objects and the `inputs[]` and `outputs[]` parameters, which are provided by Parsl.  These define the workflow by telling Parsl which things **must** happen before which other things so that the DataFlowKernel doesn't try to execute Apps in the wrong order - trying to run a function before its input data is ready, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call to EventSearch completed with exit code: 0\n"
     ]
    }
   ],
   "source": [
    "## Workflow ##\n",
    "# 1) WireDelay() takes input Threshold (.thresh) files and converts\n",
    "#    each to a Wire Delay (.wd) file:\n",
    "WireDelay_futures = []\n",
    "for i in range(len(thresholdAll)):\n",
    "        WireDelay_futures.append(WireDelay(threshIn=thresholdAll[i], outputs=[wireDelayData[i]], geoDir=geoDir, daqId=detectors[i], fw=firmwares[i]))\n",
    "\n",
    "# WireDelay_futures is a list of futures.\n",
    "# Each future has an outputs list with one output.\n",
    "WireDelay_outputs = [i.outputs[0] for i in WireDelay_futures]\n",
    "\n",
    "# 2) Combine() takes the WireDelay files output by WireDelay() and combines\n",
    "#    them into a single file with name given by --combineOut\n",
    "Combine_future = Combine(inputs=WireDelay_outputs, outputs=[combineOut])\n",
    "\n",
    "# 3) Sort() sorts the --combineOut file, producing a new file with name given\n",
    "#    by --sortOut\n",
    "Sort_future = Sort(inputs=Combine_future.outputs, outputs=[sortOut], key1=sort_sortKey1, key2=sort_sortKey2)\n",
    "\n",
    "# 4) EventSearch() processes the --sortOut file and identifies event\n",
    "#    candidates in a output file with name given by --eventCandidates\n",
    "# NB: This output file is interpreted by the e-Lab webapp, which expects it\n",
    "#    to be named \"eventCandidates\"\n",
    "EventSearch_future = EventSearch(inputs=Sort_future.outputs, outputs=[eventCandidates], gate=gate, detCoinc=detectorCoincidence, chanCoinc=channelCoincidence, eventCoinc=eventCoincidence)\n",
    "\n",
    "# Wait for the final result before exiting.\n",
    "x = EventSearch_future.result()\n",
    "\n",
    "print(\"Call to EventSearch completed with exit code:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done! The `eventCandidates` file now exists in the working directory and lists every event from the input threshold data that, according to our criteria, might have been part of a shower of cosmic rays.\n",
    "\n",
    "This will typically be a large file -- too large to read here -- but we can check what it looks like using the Bash shell's `head` utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[event number] [num events] [num hit detectors] [ID1.chan] [JD1] [Rising edge 1], [ID2.chan] [JD2] [Rising edge 2], ...\r\n",
      "#gatewidth=1.15740740740741e-11 (1000 nanoseconds), detector coincidence=1, channel coincidence=2, event coincidence=2\r\n",
      "1\t3\t1\t6203.1\t2457392\t0.2452230125667072\t6203.4\t2457392\t0.2452230125667216\t6203.2\t2457392\t0.2452230125676070\r\n",
      "2\t3\t1\t6203.1\t2457392\t0.2452298337203386\t6203.4\t2457392\t0.2452298337203386\t6203.2\t2457392\t0.2452298337212240\r\n",
      "3\t3\t1\t6203.4\t2457392\t0.2452305862390307\t6203.1\t2457392\t0.2452305862391320\t6203.4\t2457392\t0.2452305862392767\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 ./eventCandidates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
