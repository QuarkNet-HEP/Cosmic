{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instructors:*\n",
    "*This Notebook uses the Combine.pl script of the Cosmic Ray e-Lab analyses to provide material for the following learning goals:*\n",
    "\n",
    "* *Combining blocks of data to invs*\n",
    "* *The 'distance = rate x time' formula*\n",
    "* *Light Python programming to accomplish the above*\n",
    "* *Understanding how measuring devices can affect the precision of scientific data*\n",
    "* *Estimating reasonable expectations for quantitative results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarah is a data-minded track & field athlete who keeps quantitative records of her weekly training routines for the sprint, 5000 meter run, 100m hurdles, long jump, and shot put events.  She can combine this data for the past year to track her progress in each event in order to see what she's improved most at, which will tell her and her coach which training practices have been working and which haven't.\n",
    "\n",
    "There are other ways Sarah could use this data, though.  For example, if other athletes take the same data for themselves, Sarah could combine her latest training data with theirs to see what events she's currently most competitive at, which will tell her and her coach which events she should focus on for the next event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building blocks of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More data is always better than less data, especially in science.  That doesn't mean that we always want all possible data in one big chunk, though.  Storing and analyzing scientific data in smaller units gives us the flexibility to combine the data in different ways in order to investigate different questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is true of the cosmic ray data generated by QuarkNet's Cosmic Ray Muon Detectors (CRMD).  This data is stored in individual files, with each file representing data taken by a single detector over a time period of less than 24 hours.  For some studies -- say, investigating changes in cosmic ray flux as a function of fluctuations in atmospheric pressure -- we might want to look at data taken by a single detector over the course of several days.  In other studies -- say, searching for showers of cosmic rays caused by especially high-energy primary rays -- we might want to look at data taken by many detectors covering a wide geographic area, but only over the course of a few hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The e-Lab studies use the `Combine.pl` script for workflows that feature multiple input files.  As you might guess from its name, it combines data from two (or more) files into a single dataset that's contained in a single file.  This gives us the flexibility to examine the same set of raw data files in different ways: to look at extended time periods for one detector, or to look at data from more than one individual detector at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Combine.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the data transformation script `Combine.pl`, we provide it with any number of input files followed by what we want it to name the output file it creates:\n",
    "\n",
    "`$ perl ./perl/Combine.pl <input file 1> <input file 2> ... <input file N> <output file>`\n",
    "\n",
    "where the items in angled brackets `<>` are parameters we have to specify.  These are:\n",
    "\n",
    "* `input file`:  The name of a file to be used as input; we can specify as many as we like\n",
    "* `output file`: What we want to name the output file that the script will write its results to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuarkNet's cosmic ray muon detectors can take data continuously, and it's not unusual for users to run their detectors for days at a time.  For example, DAQ 6148 generated the three Threshold files\n",
    "\n",
    "`6148.2018.0602.0.thresh`\n",
    "\n",
    "`6148.2018.0603.0.thresh`\n",
    "\n",
    "and\n",
    "\n",
    "`6148.2018.0604.0.thresh`\n",
    "\n",
    "over the 3-day period from June 2 to June 4, 2018.  The Cosmic Ray e-Lab breaks such data up into individual days for the sake of organization and to keep files from becoming unmanageably large.  When running studies on the data, though, we may want to consider the entire run all at once as a single dataset.  The `Combine` data transformation lets us do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we'll start by examining the input data before we apply any transformation to it.  The following UNIX shell command will let us look at the header lines plus the first 5 and last 5 data lines of each of these three files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#$md5\r\n",
      "#md5_hex(0)\r\n",
      "#ID.CHANNEL, Julian Day, RISING EDGE(sec), FALLING EDGE(sec), TIME OVER THRESHOLD (nanosec), RISING EDGE(INT), FALLING EDGE(INT)\r\n",
      "6148.2\t2458271\t0.5001851099136574\t0.5001851099139322\t23.74\t4321599349654000\t4321599349656374\r\n",
      "6148.2\t2458271\t0.5001851099139611\t0.5001851099141927\t20.01\t4321599349656624\t4321599349658625\r\n",
      "6148.3\t2458271\t0.5001851099140625\t0.5001851099144532\t33.76\t4321599349657500\t4321599349660876\r\n",
      "6148.2\t2458271\t0.5002396629087673\t0.5002396629089699\t17.51\t4322070687531750\t4322070687533500\r\n",
      "6148.3\t2458271\t0.5002396629091435\t0.5002396629093895\t21.26\t4322070687535000\t4322070687537125\r\n",
      "...\r\n",
      "6148.4\t2458272\t0.4996444257415654\t0.4996444257419126\t30.00\t4316927838407125\t4316927838410125\r\n",
      "6148.2\t2458272\t0.4997058953934896\t0.4997058953937355\t21.24\t4317458936199750\t4317458936201875\r\n",
      "6148.3\t2458272\t0.4997058953939526\t0.4997058953940539\t8.75\t4317458936203750\t4317458936204625\r\n",
      "6148.2\t2458272\t0.4998563698267506\t0.4998563698271123\t31.25\t4318759035303125\t4318759035306250\r\n",
      "6148.3\t2458272\t0.4998563698271846\t0.4998563698274595\t23.75\t4318759035306875\t4318759035309250\r\n"
     ]
    }
   ],
   "source": [
    "!head -8 files/6148.2018.0602.0.thresh ; echo \"...\" ; tail -5 files/6148.2018.0602.0.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#$md5\r\n",
      "#md5_hex(0)\r\n",
      "#ID.CHANNEL, Julian Day, RISING EDGE(sec), FALLING EDGE(sec), TIME OVER THRESHOLD (nanosec), RISING EDGE(INT), FALLING EDGE(INT)\r\n",
      "6148.2\t2458272\t0.5002601237136719\t0.5002601237139034\t20.00\t4322247468886125\t4322247468888125\r\n",
      "6148.3\t2458272\t0.5002601237140480\t0.5002601237144098\t31.25\t4322247468889375\t4322247468892500\r\n",
      "6148.2\t2458272\t0.5002869503800058\t0.5002869503802229\t18.75\t4322479251283250\t4322479251285125\r\n",
      "6148.3\t2458272\t0.5002869503804398\t0.5002869503808015\t31.25\t4322479251287000\t4322479251290125\r\n",
      "6148.2\t2458272\t0.5003048243718605\t0.5003048243721354\t23.75\t4322633682572875\t4322633682575250\r\n",
      "...\r\n",
      "6148.3\t2458273\t0.4998297218178096\t0.4998297218180411\t20.00\t4318528796505875\t4318528796507875\r\n",
      "6148.2\t2458273\t0.4999118278728298\t0.4999118278731626\t28.75\t4319238192821250\t4319238192824125\r\n",
      "6148.2\t2458273\t0.4999118278731915\t0.4999118278733796\t16.25\t4319238192824374\t4319238192826000\r\n",
      "6148.4\t2458273\t0.4999118278733073\t0.4999118278734520\t12.50\t4319238192825375\t4319238192826625\r\n",
      "6148.3\t2458273\t0.4999118278733652\t0.4999118278736256\t22.50\t4319238192825875\t4319238192828126\r\n"
     ]
    }
   ],
   "source": [
    "!head -8 files/6148.2018.0603.0.thresh ; echo \"...\" ; tail -5 files/6148.2018.0603.0.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#$md5\r\n",
      "#md5_hex(0)\r\n",
      "#ID.CHANNEL, Julian Day, RISING EDGE(sec), FALLING EDGE(sec), TIME OVER THRESHOLD (nanosec), RISING EDGE(INT), FALLING EDGE(INT)\r\n",
      "6148.2\t2458273\t0.5003691139060619\t0.5003691139063513\t25.01\t4323189144148375\t4323189144150875\r\n",
      "6148.3\t2458273\t0.5003691139064960\t0.5003691139068287\t28.75\t4323189144152125\t4323189144155000\r\n",
      "6148.2\t2458273\t0.5004505377767506\t0.5004505377769820\t19.99\t4323892646391125\t4323892646393124\r\n",
      "6148.3\t2458273\t0.5004505377772280\t0.5004505377775318\t26.24\t4323892646395250\t4323892646397875\r\n",
      "6148.2\t2458273\t0.5004672020113861\t0.5004672020117332\t30.00\t4324036625378375\t4324036625381375\r\n",
      "...\r\n",
      "6148.3\t2458274\t0.4997994782379630\t0.4997994782382378\t23.75\t4318267491976000\t4318267491978375\r\n",
      "6148.1\t2458274\t0.4998511005815972\t0.4998511005818142\t18.75\t4318713509025000\t4318713509026875\r\n",
      "6148.3\t2458274\t0.4998511005818432\t0.4998511005820891\t21.25\t4318713509027125\t4318713509029250\r\n",
      "6148.2\t2458274\t0.4999579281848959\t0.4999579281853009\t34.99\t4319636499517500\t4319636499521000\r\n",
      "6148.3\t2458274\t0.4999579281853588\t0.4999579281855758\t18.75\t4319636499521500\t4319636499523375\r\n"
     ]
    }
   ],
   "source": [
    "!head -8 files/6148.2018.0604.0.thresh ; echo \"...\" ; tail -5 files/6148.2018.0604.0.thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the clock system the e-Lab uses to record rising and falling edge times, the value `0.5` represents midnight in [Coordinated Universal Time](https://en.wikipedia.org/wiki/Coordinated_Universal_Time) (UTC).  So, the first file (`6148.2018.0602.0.thresh`) begins just after UTC midnight on the [Julian day](https://en.wikipedia.org/wiki/Julian_day) 2458271, which is June 1, 2018 (here's a [Julian day converter](http://www.onlineconversion.com/julian_date.htm) for the curious), and it ends just before midnight on the Julian day 2458272, which is June 2, 2018.  The next two files continue this pattern into the next two days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Challenge: explain the mismatch in dates.  I think it's because the e-Labs measure days as noon-to-noon UTC, while the Julian day is midnight-to-midnight UTC.  Or, it might be a simpler time zone issue*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the number of lines in each file using the UNIX utility `wc` (short for \"word count\") with the `-l` flag to count lines instead of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23055 files/6148.2018.0602.0.thresh\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l files/6148.2018.0602.0.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23468 files/6148.2018.0603.0.thresh\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l files/6148.2018.0603.0.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23449 files/6148.2018.0604.0.thresh\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l files/6148.2018.0604.0.thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `Combine` to join these three test files into a single dataset, calling it `combineOut-6148`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ./perl/Combine.pl files/6148.2018.0602.0.thresh files/6148.2018.0603.0.thresh files/6148.2018.0604.0.thresh outputs/combineOut-6148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll examine the output file the same way we did for the input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#16457cb3f02c44fe538b5c73ef984126\r\n",
      "#md5_hex(1528996872 1529340168 1529340168 1529340169  files/6148.2018.0602.0.thresh files/6148.2018.0603.0.thresh files/6148.2018.0604.0.thresh)\r\n",
      "#Combined data for files: files/6148.2018.0602.0.thresh files/6148.2018.0603.0.thresh files/6148.2018.0604.0.thresh \r\n",
      "6148.2\t2458271\t0.5001851099136574\t0.5001851099139322\t23.74\t4321599349654000\t4321599349656374\r\n",
      "6148.2\t2458271\t0.5001851099139611\t0.5001851099141927\t20.01\t4321599349656624\t4321599349658625\r\n",
      "6148.3\t2458271\t0.5001851099140625\t0.5001851099144532\t33.76\t4321599349657500\t4321599349660876\r\n",
      "6148.2\t2458271\t0.5002396629087673\t0.5002396629089699\t17.51\t4322070687531750\t4322070687533500\r\n",
      "6148.3\t2458271\t0.5002396629091435\t0.5002396629093895\t21.26\t4322070687535000\t4322070687537125\r\n",
      "...\r\n",
      "6148.3\t2458274\t0.4997994782379630\t0.4997994782382378\t23.75\t4318267491976000\t4318267491978375\r\n",
      "6148.1\t2458274\t0.4998511005815972\t0.4998511005818142\t18.75\t4318713509025000\t4318713509026875\r\n",
      "6148.3\t2458274\t0.4998511005818432\t0.4998511005820891\t21.25\t4318713509027125\t4318713509029250\r\n",
      "6148.2\t2458274\t0.4999579281848959\t0.4999579281853009\t34.99\t4319636499517500\t4319636499521000\r\n",
      "6148.3\t2458274\t0.4999579281853588\t0.4999579281855758\t18.75\t4319636499521500\t4319636499523375\r\n"
     ]
    }
   ],
   "source": [
    "!head -8 outputs/combineOut-6148; echo \"...\" ; tail -5 outputs/combineOut-6148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see at a glance that the first five data lines of the output are the first five data lines of the first input file, and the last five data lines of the output are the same as the last five data lines of the last input file.  That's what we'd expect for a transformation that does nothing but concatenate files together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, we can check the line count of the output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69966 outputs/combineOut-6148\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l outputs/combineOut-6148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this number what you expect it to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it's almost, but not quite, equal to the sum of the line counts of each of the individual input files,\n",
    "\n",
    "```\n",
    "23055 + 23468 + 23449 = 69972\n",
    "```\n",
    "\n",
    "Why are the two counts not exactly equal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data over place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Combine` data transformation script also allows us to join data from two different sources into a single dataset.  For example, we may wish to look at data taken at the same time by two nearby detectors to see if there are any correlations in muon events between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try that with the following two files containing data taken by detectors 6148 and 6478 at Fermilab on May 7, 2017:\n",
    "\n",
    "`6148.2017.0507.0.thresh`\n",
    "\n",
    "`6478.2017.0507.0.thresh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll do the same trick with the UNIX `head` and `tail` commands to see the beginning and end of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#$md5\r\n",
      "#md5_hex(0)\r\n",
      "#ID.CHANNEL, Julian Day, RISING EDGE(sec), FALLING EDGE(sec), TIME OVER THRESHOLD (nanosec), RISING EDGE(INT), FALLING EDGE(INT)\r\n",
      "6148.1\t2457880\t0.5017287926934751\t0.5017287926938802\t34.99\t4334936768871625\t4334936768875125\r\n",
      "6148.1\t2457880\t0.5017287926939091\t0.5017287926941262\t18.75\t4334936768875375\t4334936768877250\r\n",
      "6148.4\t2457880\t0.5017287926940828\t0.5017287926943577\t23.75\t4334936768876876\t4334936768879250\r\n",
      "6148.2\t2457880\t0.5030325167516059\t0.5030325167520978\t42.50\t4346200944733875\t4346200944738125\r\n",
      "6148.1\t2457880\t0.5030325167519096\t0.5030325167522569\t30.00\t4346200944736500\t4346200944739500\r\n",
      "...\r\n",
      "6148.2\t2457881\t0.4991468762158276\t0.4991468762161170\t25.00\t4312629010504750\t4312629010507250\r\n",
      "6148.1\t2457881\t0.4991468762158854\t0.4991468762162615\t32.49\t4312629010505250\t4312629010508500\r\n",
      "6148.2\t2457881\t0.4996565376225549\t0.4996565376225984\t3.76\t4317032485058874\t4317032485059250\r\n",
      "6148.3\t2457881\t0.4996565376228299\t0.4996565376230469\t18.75\t4317032485061250\t4317032485063125\r\n",
      "6148.3\t2457881\t0.4996565376231048\t0.4996565376232638\t13.75\t4317032485063625\t4317032485065000\r\n"
     ]
    }
   ],
   "source": [
    "!head -8 files/6148.2017.0507.0.thresh; echo \"...\" ; tail -5 files/6148.2017.0507.0.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#$md5\r\n",
      "#md5_hex(0)\r\n",
      "#ID.CHANNEL, Julian Day, RISING EDGE(sec), FALLING EDGE(sec), TIME OVER THRESHOLD (nanosec), RISING EDGE(INT), FALLING EDGE(INT)\r\n",
      "6478.2\t2457880\t0.5801056986752026\t0.5801056986755063\t26.24\t5012113236553750\t5012113236556375\r\n",
      "6478.1\t2457880\t0.5801056986751737\t0.5801056986756077\t37.50\t5012113236553501\t5012113236557250\r\n",
      "6478.3\t2457880\t0.5801059826235389\t0.5801059826239294\t33.75\t5012115689867375\t5012115689870750\r\n",
      "6478.4\t2457880\t0.5801059826234953\t0.5801059826238426\t30.00\t5012115689867000\t5012115689870000\r\n",
      "6478.4\t2457880\t0.5801063615076100\t0.5801063615078559\t21.25\t5012118963425750\t5012118963427875\r\n",
      "...\r\n",
      "6478.4\t2457881\t0.1316323887125434\t0.1316323887129051\t31.25\t1137303838476375\t1137303838479500\r\n",
      "6478.1\t2457881\t0.1316350724972946\t0.1316350724976128\t27.50\t1137327026376625\t1137327026379375\r\n",
      "6478.2\t2457881\t0.1316350724973235\t0.1316350724975984\t23.75\t1137327026376875\t1137327026379250\r\n",
      "6478.2\t2457881\t0.1316383624849537\t0.1316383624852720\t27.50\t1137355451870000\t1137355451872750\r\n",
      "6478.1\t2457881\t0.1316383624849248\t0.1316383624853154\t33.75\t1137355451869750\t1137355451873125\r\n"
     ]
    }
   ],
   "source": [
    "!head -8 files/6478.2017.0507.0.thresh; echo \"...\" ; tail -5 files/6478.2017.0507.0.thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first file, `6148.2017.0507.0.thresh`, covers the whole UTC day midnight-to-midnight (equivalent to the Julian day noon 2457880 - noon 2457881).  The second file, `6478.2017.0507.0.thresh` covers a time period fully within that of the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, we'll take a look at the line counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4424 files/6148.2017.0507.0.thresh\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l files/6148.2017.0507.0.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776 files/6478.2017.0507.0.thresh\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l files/6478.2017.0507.0.thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed these two input files into the data transformation script `Combine`, calling the output file `combineOut-05072017`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ./perl/Combine.pl files/6148.2017.0507.0.thresh files/6478.2017.0507.0.thresh outputs/combineOut-05072017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And examine the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#90995444efbf33e84090296aa80383c4\r\n",
      "#md5_hex(1528996872 1498068825 1494356148  files/6148.2017.0507.0.thresh files/6478.2017.0507.0.thresh)\r\n",
      "#Combined data for files: files/6148.2017.0507.0.thresh files/6478.2017.0507.0.thresh \r\n",
      "6148.1\t2457880\t0.5017287926934751\t0.5017287926938802\t34.99\t4334936768871625\t4334936768875125\r\n",
      "6148.1\t2457880\t0.5017287926939091\t0.5017287926941262\t18.75\t4334936768875375\t4334936768877250\r\n",
      "6148.4\t2457880\t0.5017287926940828\t0.5017287926943577\t23.75\t4334936768876876\t4334936768879250\r\n",
      "6148.2\t2457880\t0.5030325167516059\t0.5030325167520978\t42.50\t4346200944733875\t4346200944738125\r\n",
      "6148.1\t2457880\t0.5030325167519096\t0.5030325167522569\t30.00\t4346200944736500\t4346200944739500\r\n",
      "6148.1\t2457880\t0.5031973088185040\t0.5031973088187355\t20.00\t4347624748191875\t4347624748193875\r\n",
      "6148.1\t2457880\t0.5031973088187789\t0.5031973088189960\t18.76\t4347624748194250\t4347624748196126\r\n",
      "6148.2\t2457880\t0.5031973088185330\t0.5031973088189815\t38.75\t4347624748192125\t4347624748196000\r\n",
      "6148.1\t2457880\t0.5031973088190539\t0.5031973088190972\t3.74\t4347624748196626\t4347624748197000\r\n",
      "6148.2\t2457880\t0.5042477725158564\t0.5042477725162616\t35.01\t4356700754537000\t4356700754540500\r\n",
      "...\r\n",
      "6478.2\t2457881\t0.1316312090077836\t0.1316312090083189\t46.25\t1137293645827250\t1137293645831875\r\n",
      "6478.1\t2457881\t0.1316312090081742\t0.1316312090083622\t16.25\t1137293645830625\t1137293645832250\r\n",
      "6478.3\t2457881\t0.1316319511278067\t0.1316319511280961\t25.00\t1137300057744250\t1137300057746750\r\n",
      "6478.4\t2457881\t0.1316319511277633\t0.1316319511281539\t33.75\t1137300057743875\t1137300057747250\r\n",
      "6478.3\t2457881\t0.1316323887126158\t0.1316323887128472\t20.00\t1137303838477000\t1137303838479000\r\n",
      "6478.4\t2457881\t0.1316323887125434\t0.1316323887129051\t31.25\t1137303838476375\t1137303838479500\r\n",
      "6478.1\t2457881\t0.1316350724972946\t0.1316350724976128\t27.50\t1137327026376625\t1137327026379375\r\n",
      "6478.2\t2457881\t0.1316350724973235\t0.1316350724975984\t23.75\t1137327026376875\t1137327026379250\r\n",
      "6478.2\t2457881\t0.1316383624849537\t0.1316383624852720\t27.50\t1137355451870000\t1137355451872750\r\n",
      "6478.1\t2457881\t0.1316383624849248\t0.1316383624853154\t33.75\t1137355451869750\t1137355451873125\r\n"
     ]
    }
   ],
   "source": [
    "!head -13 outputs/combineOut-05072017; echo \"...\" ; tail -10 outputs/combineOut-05072017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12197 outputs/combineOut-05072017\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l outputs/combineOut-05072017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line count looks like what we expect for combining two files of 4424 lines and 7776 lines, respectively.  However, there's one other aspect of this output we might not have expected: all of the DAQ 6148 data is at the beginning of the file, while all of the 6478 data is at the end of the file, even though the 6478 muon events were mixed in with the 6148 muon events over the time period that this data was collected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't a mistake at all, of course.  The `Combine` data transformation does just what its name implies, and only that: it joins two or more files into a single file.  Re-arranging the lines of data to put them in order of time is a separate data transformation handled by a separate script; we'll examine that one soon enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
