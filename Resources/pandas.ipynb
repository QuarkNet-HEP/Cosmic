{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` is a Python package created to aid with data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the package, place this import statement at the top of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(in a Jupyter Notebook, it's okay to have cells above the import, but this should come before any other Python code).  Nearly all `pandas` users import the library under the name `pd` to save typing when calling its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you, for example, to call `pandas`'s `read_csv()` function as `pd.read_csv()` instead of the longer `pandas.read_csv()`.  We'll do this in the future, but for this introduction we'll leave it as `pandas` to help clarify which functions are coming from `pandas` and which are standard Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` package defines a `DataFrame` object and uses it to manage data.  A `DataFrame` organizes data into a 2-dimensional array similar to a spreadsheet or database table.  `DataFrame`s can be created manually within the code, or they can be read in from an external file using one of several functions `pandas` includes for this purpose.  One such function is `pandas.read_csv()`, designed to import data from CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas.read_csv()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.read_csv()` takes a CSV data file and automatically converts it into a `DataFrame` object.  Below, we assign that object to the variable `myDataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataFrame = pandas.read_csv('path/to/file.csv')   # Not a real file, don't try to run this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location of the CSV file to read is the only *required* argument; it should be given as a string (that is, enclosed by single or double quotes).  The file path can be either absolute or relative to the location where you're working.  For Jupyter Notebooks, that's the directory where the `jupyter notebook` program was started (unless configured otherwise), and for these notebooks that's usually `/Users/QuarkNet/Jupyter/`.\n",
    "\n",
    "If necessary, you can check your current working directory using the UNIX `pwd` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jgriffith/git_project_roots/Cosmic/Resources\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the required \"name of the file to read,\" `pandas.read_csv()` also accepts several *optional* arguments that can make life easier for you:\n",
    "\n",
    "* `names=['column1', 'column2', 'column3', ...]`<br>\n",
    "    allows you to specify the names of the columns in the CSV file as strings.  Of course, the number of items in `names` must match the number of columns `pandas.csv()` reads from the file.\n",
    "    \n",
    "    \n",
    "* `header=None`<br>\n",
    "    prevents `pandas.csv()` from importing header information as data.  Normally, the file header of a CSV file is a list of its column names, but it could be more complicated than that.  Our cosmic ray data files, for example, have an extensive preamble that `header=None` eliminates.\n",
    "    \n",
    "    \n",
    "* `skiprows=N`<br>\n",
    "    tells `pandas.csv()` to skip the first `N` lines of the input file, with `N` given as an integer number (not a string).  This is another potentially useful approach to removing the cosmic ray data preamble lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) has more examples.  We'll add them to the above list as we discover and use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've read in the data you want to analyze and assigned the resulting `DataFrame` to a variable, `pandas` provides a variety of functions to show and manipulated the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing cosmic ray data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `with` in this manner ensures that the file is closed when it's no longer needed, even if there's an error, which prevents runaway memory usage and file corruption problems.\n",
    "\n",
    "The above code reads in `dataIn` line-by-line, using the `enumerate()` function to include line numbers along with the lines.  When we hit the line `ST Enabled, scalar data plus reset counters`, we know we're about to start the real cosmic ray data lines, so we record this line number as `indicatorLine`.  We then `break` because we don't need to read in any more at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
